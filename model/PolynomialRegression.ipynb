{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlXUvnFrzvRVeAqXFKdyfI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook expects a previows data processing pipeline, that defines four variables: `X_train`, `X_test`, `y_train`, `y_test`\n",
        "\n"
      ],
      "metadata": {
        "id": "Xlwgsl062pPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9J7GWGc1_tT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensors = Variable(torch.Tensor(X_train))\n",
        "X_test_tensors = Variable(torch.Tensor(X_test))\n",
        "\n",
        "y_train_tensors = Variable(torch.Tensor(y_train))\n",
        "y_test_tensors = Variable(torch.Tensor(y_test))\n",
        "\n",
        "#reshaping to rows, timestamps, features\n",
        "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
        "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))\n",
        "\n",
        "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
        "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape)"
      ],
      "metadata": {
        "id": "V_BKUhkE4WdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PolynomialRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(PolynomialRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Amq88n8M4XPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000 #1000 epochs\n",
        "learning_rate = 0.001 #0.001 lr\n",
        "\n",
        "input_size = 5 #number of features\n",
        "hidden_size = 2 #number of features in hidden state\n",
        "num_layers = 1 #number of stacked lstm layers\n",
        "\n",
        "num_classes = 1 #number of output classes\n",
        "\n"
      ],
      "metadata": {
        "id": "_4gnKWtj5Vic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialRegressionModel(X_train_tensors_final.shape[1])\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(poly.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = poly.forward(X_train_tensors_final) #forward pass\n",
        "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
        "\n",
        "  # obtain the loss function\n",
        "  loss = criterion(outputs, y_train_tensors)\n",
        "\n",
        "  loss.backward() #calculates the loss of the loss function\n",
        "\n",
        "  optimizer.step() #improve from loss, i.e backprop\n",
        "  if epoch % 100 == 0:\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "metadata": {
        "id": "kIk-9ojl5lIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_ss = ss.transform(df.iloc[:, :-1]) #old transformers\n",
        "df_y_mm = mm.transform(df.iloc[:, -1:]) #old transformers\n",
        "\n",
        "df_X_ss = Variable(torch.Tensor(df_X_ss)) #converting to Tensors\n",
        "df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
        "#reshaping the dataset\n",
        "df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1]))"
      ],
      "metadata": {
        "id": "q9f7XSGe7Etd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = poly(df_X_ss)#forward pass\n",
        "data_predict = train_predict.data.numpy() #numpy conversion\n",
        "dataY_plot = df_y_mm.data.numpy()\n",
        "\n",
        "data_predict = mm.inverse_transform(data_predict) #reverse transformation\n",
        "dataY_plot = mm.inverse_transform(dataY_plot)\n",
        "plt.figure(figsize=(10,6)) #plotting\n",
        "plt.axvline(x=200, c='r', linestyle='--') #size of the training set\n",
        "\n",
        "plt.plot(dataY_plot, label='Actuall Data') #actual plot\n",
        "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
        "plt.title('Time-Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "24qArpoD7Ml7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}